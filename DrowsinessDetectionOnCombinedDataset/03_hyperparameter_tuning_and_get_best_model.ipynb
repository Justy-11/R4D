{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd0aa65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14970084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train, test, validation splits\n",
    "saved_dir = 'D:/JATHURSH/Jupyter_notebook_projects/DrowsinessDetectionOnCombinedDataset/saved_data/train_test_val_splits_preprocessed_combined_dataset/'\n",
    "\n",
    "X_train = np.load(saved_dir + 'X_train.npy')\n",
    "\n",
    "X_val = np.load(saved_dir + 'X_val.npy')\n",
    "\n",
    "y_train = np.load(saved_dir + 'y_train.npy')\n",
    "\n",
    "y_val = np.load(saved_dir + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52756b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # pretrained model - MobileNetV2\n",
    "    # all should be numpy arrays or tensors before giving it to MobileNetV2\n",
    "    \"\"\"\n",
    "    tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    input_shape=None,                 # Shape of input data (MobileNets support any input size greater than 32 x 32, with larger image sizes offering better performance.) \n",
    "    alpha=1.0,                        # Width multiplier for controlling network width (default is 1.0)\n",
    "    include_top=True,                 # Include fully connected top layers (default is True)\n",
    "    weights='imagenet',               # Weight initialization ('imagenet' for pre-trained weights, None for random initialization)\n",
    "    input_tensor=None,                # Optional input tensor (default is None)\n",
    "    pooling=None,                     # Pooling type for the last layer ('avg', 'max', or None; default is None)\n",
    "    classes=1000,                     # Number of output classes (default is 1000 for ImageNet)\n",
    "    classifier_activation='softmax',   # Activation function for output layer (default is 'softmax')\n",
    "    **kwargs                          # Additional keyword arguments\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    # we dont have to set anything and keep its default values\n",
    "    MobileNetV2_model = tf.keras.applications.mobilenet_v2.MobileNetV2()\n",
    "    \n",
    "    # Make all layers in the model non-trainable - freeze\n",
    "    for layer in MobileNetV2_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    base_input = MobileNetV2_model.layers[0].input\n",
    "    base_output = MobileNetV2_model.layers[-3].output\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_output)\n",
    "    \n",
    "    # Hyperparameter: Include Dense Layer (True or False)\n",
    "    include_dense = hp.Boolean('include_dense')\n",
    "\n",
    "    if include_dense:\n",
    "        # Hyperparameter: Number of neurons in the dense layer\n",
    "        num_neurons = hp.Int('num_neurons', min_value=32, max_value=512, step=32)\n",
    "        dense_layer = tf.keras.layers.Dense(num_neurons, activation='relu')(global_average_layer)\n",
    "        # Hyperparameter: Dropout rate\n",
    "        '''\n",
    "        Dropout is a regularization technique that helps prevent overfitting by randomly \n",
    "        setting a fraction of the input units to 0 during training.\n",
    "        '''\n",
    "        dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "        dropout_layer = tf.keras.layers.Dropout(dropout_rate)(dense_layer)\n",
    "        final_output = tf.keras.layers.Dense(1)(dropout_layer)\n",
    "    else:\n",
    "        final_output = tf.keras.layers.Dense(1)(global_average_layer)\n",
    "        \n",
    "    final_output = tf.keras.layers.Activation(\"sigmoid\")(final_output)\n",
    "    \n",
    "    drowsiness_detection_model = tf.keras.Model(inputs=base_input, outputs=final_output)\n",
    "    \n",
    "    # Hyperparameter: Learning rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    drowsiness_detection_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return drowsiness_detection_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d79d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Keras Tuner RandomSearch tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # The metric to optimize\n",
    "    max_trials=10,             # Number of hyperparameter combinations to try\n",
    "    directory='tuner_dir',      # Directory for saving results\n",
    "    project_name='drowsiness_detection_tuner'  # Name of the project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cbbcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [03h 04m 41s]\n",
      "val_accuracy: 0.9693187475204468\n",
      "\n",
      "Best val_accuracy So Far: 0.9694488048553467\n",
      "Total elapsed time: 2d 15h 10m 58s\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter: Batch size\n",
    "batch_size = 32 # hp.Int('batch_size', min_value=16, max_value=128, step=16)\n",
    "\n",
    "# Use the ReduceLROnPlateau learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    ")\n",
    "    \n",
    "# Start the hyperparameter search using your training data with early stopping\n",
    "tuner.search(X_train, y_train,\n",
    "             epochs=100, \n",
    "             validation_data=(X_val, y_val), \n",
    "             batch_size=batch_size,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=5), lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec78419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tuner_dir\\drowsiness_detection_tuner\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.001\n",
      "num_neurons: 224\n",
      "dropout_rate: 0.0\n",
      "Score: 0.9694488048553467\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.001\n",
      "num_neurons: 416\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9693187475204468\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.0001\n",
      "num_neurons: 288\n",
      "dropout_rate: 0.2\n",
      "Score: 0.9680187106132507\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.0001\n",
      "num_neurons: 192\n",
      "dropout_rate: 0.0\n",
      "Score: 0.9677587151527405\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.001\n",
      "num_neurons: 32\n",
      "dropout_rate: 0.0\n",
      "Score: 0.9673687219619751\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.0001\n",
      "Score: 0.9619084596633911\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.0001\n",
      "num_neurons: 384\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9613884687423706\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.001\n",
      "Score: 0.9604784250259399\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.01\n",
      "num_neurons: 160\n",
      "dropout_rate: 0.2\n",
      "Score: 0.9600884318351746\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.01\n",
      "num_neurons: 416\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9570983052253723\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b3865",
   "metadata": {},
   "source": [
    "When include_dense is set to False, the values for num_neurons and dropout_rate are still generated as hyperparameters, but they won't be used in creating the dense layer or dropout layer in the model. In this case, those hyperparameters are effectively placeholders, and their values are not used because you've excluded the dense layer from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a36aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'include_dense': True,\n",
       " 'learning_rate': 0.001,\n",
       " 'num_neurons': 224,\n",
       " 'dropout_rate': 0.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75326cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
