
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ea674d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "238da0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed train, validation splits - for X (features)\n",
    "preprocessed_saved_dir = 'D:/JATHURSH/Jupyter_notebook_projects/DistractionDetection/saved_data/train_val_test_preprocessed/'\n",
    "# for y - (labels)\n",
    "split_saved_dir = 'D:/JATHURSH/Jupyter_notebook_projects/DistractionDetection/saved_data/train_val_split/'\n",
    "\n",
    "X_train = np.load(preprocessed_saved_dir + 'X_train_preprocessed.npy')\n",
    "\n",
    "X_val = np.load(preprocessed_saved_dir + 'X_val_preprocessed.npy')\n",
    "\n",
    "y_train = np.load(split_saved_dir + 'y_train.npy')\n",
    "\n",
    "y_val = np.load(split_saved_dir + 'y_val.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39c474b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 2, ..., 0, 6, 8]), array([0, 1, 6, ..., 4, 0, 8]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8c4e1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32),\n",
       " array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding the lebels\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, num_classes=10)\n",
    "y_val_encoded = to_categorical(y_val, num_classes=10)\n",
    "y_train_encoded, y_val_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb2c304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # pretrained model - MobileNetV2\n",
    "    # all should be numpy arrays or tensors before giving it to MobileNetV2\n",
    "    \"\"\"\n",
    "    tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    input_shape=None,                 # Shape of input data (MobileNets support any input size greater than 32 x 32, with larger image sizes offering better performance.) \n",
    "    alpha=1.0,                        # Width multiplier for controlling network width (default is 1.0)\n",
    "    include_top=True,                 # Include fully connected top layers (default is True)\n",
    "    weights='imagenet',               # Weight initialization ('imagenet' for pre-trained weights, None for random initialization)\n",
    "    input_tensor=None,                # Optional input tensor (default is None)\n",
    "    pooling=None,                     # Pooling type for the last layer ('avg', 'max', or None; default is None)\n",
    "    classes=1000,                     # Number of output classes (default is 1000 for ImageNet)\n",
    "    classifier_activation='softmax',   # Activation function for output layer (default is 'softmax')\n",
    "    **kwargs                          # Additional keyword arguments\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    # we dont have to set anything and keep its default values\n",
    "    MobileNetV2_model = tf.keras.applications.mobilenet_v2.MobileNetV2()\n",
    "    \n",
    "    # Make all layers in the model non-trainable - freeze\n",
    "    for layer in MobileNetV2_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    base_input = MobileNetV2_model.layers[0].input\n",
    "    base_output = MobileNetV2_model.layers[-3].output\n",
    "    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()(base_output)\n",
    "    \n",
    "    # Hyperparameter: Include Dense Layer (True or False)\n",
    "    include_dense = hp.Boolean('include_dense')\n",
    "\n",
    "    if include_dense:\n",
    "        # Hyperparameter: Number of neurons in the dense layer\n",
    "        num_neurons = hp.Int('num_neurons', min_value=32, max_value=512, step=32)\n",
    "        dense_layer = tf.keras.layers.Dense(num_neurons, activation='relu')(global_average_layer)\n",
    "        # Hyperparameter: Dropout rate\n",
    "        '''\n",
    "        Dropout is a regularization technique that helps prevent overfitting by randomly \n",
    "        setting a fraction of the input units to 0 during training.\n",
    "        '''\n",
    "        dropout_rate = hp.Float('dropout_rate', min_value=0.0, max_value=0.5, step=0.1)\n",
    "        dropout_layer = tf.keras.layers.Dropout(dropout_rate)(dense_layer)\n",
    "        \n",
    "        final_output = tf.keras.layers.Dense(10, activation='softmax')(dropout_layer)\n",
    "    else:\n",
    "        final_output = tf.keras.layers.Dense(10, activation='softmax')(global_average_layer)\n",
    "    \n",
    "    distraction_detection_model = tf.keras.Model(inputs=base_input, outputs=final_output)\n",
    "    \n",
    "    # Hyperparameter: Learning rate\n",
    "    learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "    distraction_detection_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy', # Use categorical cross-entropy for multi-class classification\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return distraction_detection_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "595c5deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Keras Tuner RandomSearch tuner\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',  # The metric to optimize\n",
    "    max_trials=10,             # Number of hyperparameter combinations to try\n",
    "    directory='tuner_dir',      # Directory for saving results\n",
    "    project_name='distraction_detection'  # Name of the project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882ec5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [02h 29m 38s]\n",
      "val_accuracy: 0.7320553064346313\n",
      "\n",
      "Best val_accuracy So Far: 0.9915292263031006\n",
      "Total elapsed time: 1d 07h 01m 02s\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter: Batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Use the ReduceLROnPlateau learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    ")\n",
    "    \n",
    "# Start the hyperparameter search using your training data with early stopping\n",
    "tuner.search(X_train, y_train_encoded,\n",
    "             epochs=50, \n",
    "             validation_data=(X_val, y_val_encoded), \n",
    "             batch_size=batch_size,\n",
    "             callbacks=[tf.keras.callbacks.EarlyStopping(patience=5), lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80a6d4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in tuner_dir\\distraction_detection\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.0001\n",
      "num_neurons: 160\n",
      "dropout_rate: 0.2\n",
      "Score: 0.9915292263031006\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.001\n",
      "num_neurons: 256\n",
      "dropout_rate: 0.4\n",
      "Score: 0.9897458553314209\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.001\n",
      "num_neurons: 192\n",
      "dropout_rate: 0.30000000000000004\n",
      "Score: 0.9852875471115112\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.001\n",
      "num_neurons: 96\n",
      "dropout_rate: 0.0\n",
      "Score: 0.9826125502586365\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.001\n",
      "num_neurons: 32\n",
      "dropout_rate: 0.0\n",
      "Score: 0.9808292388916016\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.01\n",
      "num_neurons: 32\n",
      "dropout_rate: 0.30000000000000004\n",
      "Score: 0.975479245185852\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.0001\n",
      "num_neurons: 256\n",
      "dropout_rate: 0.0\n",
      "Score: 0.9741417765617371\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "include_dense: False\n",
      "learning_rate: 0.01\n",
      "num_neurons: 128\n",
      "dropout_rate: 0.30000000000000004\n",
      "Score: 0.9661167860031128\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.01\n",
      "num_neurons: 224\n",
      "dropout_rate: 0.30000000000000004\n",
      "Score: 0.7320553064346313\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "include_dense: True\n",
      "learning_rate: 0.01\n",
      "num_neurons: 32\n",
      "dropout_rate: 0.30000000000000004\n",
      "Score: 0.1176995113492012\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1915b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'include_dense': True,\n",
       " 'learning_rate': 0.0001,\n",
       " 'num_neurons': 160,\n",
       " 'dropout_rate': 0.2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner.get_best_hyperparameters()[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5230d574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
